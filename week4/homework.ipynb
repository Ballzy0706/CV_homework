{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.grad in torch:tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]]) \n",
      " W.grad by manual:tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]], grad_fn=<MmBackward0>) \n",
      "\n",
      "x.grad in torch:tensor([[  1.1002,   0.0860,   5.3377,   0.2788],\n",
      "        [  0.9583,  10.4633, -13.5234, -16.3639],\n",
      "        [ -0.8712,  -0.9272,  -0.7764,   2.0790],\n",
      "        [ -1.4504,   5.6914,   0.7613,  -0.9693],\n",
      "        [ -1.2892,  -3.4714,  -1.9788,   4.8091],\n",
      "        [ -4.0523,  -4.3127,  -3.6114,   9.6703],\n",
      "        [ -0.7312,  -0.7782,  -0.6516,   1.7449],\n",
      "        [ -0.8191,  -0.8718,  -0.7300,   1.9547],\n",
      "        [  1.0350,   2.9930,  -6.6743,  -7.5333],\n",
      "        [ -2.4616,  -2.4243,  -2.1164,   5.7128]]) \n",
      " x.grad by manual:tensor([[  1.1002,   0.0860,   5.3377,   0.2788],\n",
      "        [  0.9583,  10.4633, -13.5234, -16.3639],\n",
      "        [ -0.8712,  -0.9272,  -0.7764,   2.0790],\n",
      "        [ -1.4504,   5.6914,   0.7613,  -0.9693],\n",
      "        [ -1.2892,  -3.4714,  -1.9788,   4.8091],\n",
      "        [ -4.0523,  -4.3127,  -3.6114,   9.6703],\n",
      "        [ -0.7312,  -0.7782,  -0.6516,   1.7449],\n",
      "        [ -0.8191,  -0.8718,  -0.7300,   1.9547],\n",
      "        [  1.0350,   2.9930,  -6.6743,  -7.5333],\n",
      "        [ -2.4616,  -2.4243,  -2.1164,   5.7128]], grad_fn=<MmBackward0>) \n",
      "\n",
      "y.grad in torch:tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]]) \n",
      " y.grad by manual:tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]],\n",
      "       grad_fn=<MulBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(10,4, requires_grad=True)\n",
    "W = torch.randn(4,4, requires_grad=True)\n",
    "y = torch.randn(10,4, requires_grad=True)\n",
    "f = (torch.clamp(x.mm(W), 0) - y).pow(2).sum()\n",
    "f.backward()\n",
    "\n",
    "z = x.mm(W)\n",
    "y_hat = torch.clamp(z, 0)\n",
    "f = (y_hat - y).pow(2).sum()\n",
    "\n",
    "W_grad = 2 * (x.T) @ ((y_hat-y)*torch.where(z>0, 1, 0))\n",
    "x_grad = 2 * ((y_hat-y)*torch.where(z>0, 1, 0)) @ (W.T)\n",
    "y_grad = -2 * (y_hat-y)\n",
    "print(f\"W.grad in torch:{W.grad} \\n\", f\"W.grad by manual:{W_grad} \\n\")\n",
    "print(f\"x.grad in torch:{x.grad} \\n\", f\"x.grad by manual:{x_grad} \\n\")\n",
    "print(f\"y.grad in torch:{y.grad} \\n\", f\"y.grad by manual:{y_grad} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "01749d67749c07299eb0ff97c69d1ce880e7c9e6ec8c46243b3a87c233b9e7dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
